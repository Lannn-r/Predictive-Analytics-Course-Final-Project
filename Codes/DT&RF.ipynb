{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom IPython.display import Image\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB, GaussianNB\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.tree import export_text\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import resample\nfrom sklearn import metrics",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"Cleaned_data_Label_Encoding_version_final.csv\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Normalize\ny = df[\"Price\"]\nX = df.drop(columns=[\"Price\"])\nscaler = MinMaxScaler()\nX = pd.DataFrame(scaler.fit_transform(X),columns=X.columns)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=240)\ndef create_cm(t1, t2):\n    cm = confusion_matrix(t1, t2)\n    plt.matshow(cm)\n    plt.title('Confusion matrix')\n    plt.colorbar()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Oversampling Minority\ndf[\"Price\"].value_counts()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#combine our training info back together for now\nX =X_train\nX['Price'] = y_train\n\n# separate minority and majority classes\nnot_churn = X[X['Price']==1] #majority\nchurn = X[X['Price']==0] #minority\nchurn_2 = X[X['Price']==2] #minority\n\nprint(not_churn.shape)\nprint(churn.shape)\nprint(churn_2.shape)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# upsample minority\nchurn_upsampled = resample(churn, replace=True, # sample with replacement\n                           n_samples=len(not_churn), # match number in majority class\n                           random_state=27) # reproducible results\n\nchurn_upsampled_2 = resample(churn_2, replace=True, # sample with replacement\n                           n_samples=len(not_churn), # match number in majority class\n                           random_state=27) # reproducible results\n\n# combine majority and upsampled minority\nupsampled = pd.concat([not_churn, churn_upsampled, churn_upsampled_2])\n\n# check new class counts\nupsampled['Price'].value_counts()\n\n# split our X and y back out\ny_train_over = upsampled['Price']\nX_train_over = upsampled.drop('Price', axis=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Undersampling Majority\nX =X_train\nX['Price'] = y_train\n\nnot_churn = X[X['Price']==1]\nchurn = X[X['Price']==0]\nchurn_2 = X[X['Price']==2]\nprint(not_churn.shape)\nprint(churn.shape)\nprint(len(not_churn))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "not_churn_downsampled = resample(not_churn,\n                                replace = False, # sample without replacement\n                                #n_samples = len(churn), # match minority n\n                                n_samples = len(churn), # create 2:1 ratio\n                                random_state = 27) # reproducible results\n\n# combine minority and downsampled majority\ndownsampled = pd.concat([not_churn_downsampled,churn_2, churn])\n\n# checking counts\ndownsampled['Price'].value_counts()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "y_train_under = downsampled['Price']\nX_train_under = downsampled.drop('Price', axis=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Decision Tree\n# DT - no imbalance process\nX_train = X_train.drop(columns=['Price'])\n\ndt = DecisionTreeClassifier(criterion = \"entropy\",random_state = 242)\ndt.fit(X_train, y_train)\nprint(dt.tree_.max_depth)\nprint(dt.tree_.n_leaves)\ndt_pred = dt.predict(X_test)\n\n\nprint(pd.crosstab(dt_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,dt_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dt = DecisionTreeClassifier(criterion = \"gini\",random_state = 242)\ndt.fit(X_train, y_train)\nprint(dt.tree_.max_depth)\nprint(dt.tree_.n_leaves)\ndt_pred = dt.predict(X_test)\n\nprint(dt.score(X_test, y_test))\npd.crosstab(dt_pred, y_test, rownames = [\"Predicted\"], colnames = [\"Actual\"])\n\nprint(pd.crosstab(dt_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,dt_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "path = dt.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\nfig, ax = plt.subplots()\nax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\nax.set_xlabel(\"effective alpha\")\nax.set_ylabel(\"total impurity of leaves\")\nax.set_title(\"Total Impurity vs effective alpha for training set\")\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dt.fit(X_train, y_train)\nprint(dt.tree_.max_depth)\nprint(dt.tree_.n_leaves)\ndt_pred = dt.predict(X_test)\n\nprint(dt.score(X_test, y_test))\npd.crosstab(dt_pred, y_test, rownames = [\"Predicted\"], colnames = [\"Actual\"])\n\nprint(pd.crosstab(dt_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,dt_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X = X.drop(columns=['Price'])\n\ntext_tree = export_text(dt, feature_names = list(X.columns))\nprint(text_tree)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(250,200))\ntree.plot_tree(dt, feature_names = X_train.columns,  filled=True)\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## DT - Oversampling\ndt.fit(X_train_over, y_train_over)\nprint(dt.tree_.max_depth)\nprint(dt.tree_.n_leaves)\ndt_pred = dt.predict(X_test)\n\nprint(dt.score(X_test, y_test))\n\nprint(pd.crosstab(dt_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,dt_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "path = dt.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\nfig, ax = plt.subplots()\nax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\nax.set_xlabel(\"effective alpha\")\nax.set_ylabel(\"total impurity of leaves\")\nax.set_title(\"Total Impurity vs effective alpha for training set\")\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## DT - Undersampling\ndt.fit(X_train_under, y_train_under)\nprint(dt.tree_.max_depth)\nprint(dt.tree_.n_leaves)\ndt_pred = dt.predict(X_test)\n\nprint(dt.score(X_test, y_test))\nprint(pd.crosstab(dt_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,dt_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "path = dt.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\nfig, ax = plt.subplots()\nax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\nax.set_xlabel(\"effective alpha\")\nax.set_ylabel(\"total impurity of leaves\")\nax.set_title(\"Total Impurity vs effective alpha for training set\")\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Random Forest\n### RF - No Imbalance Process\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\n\nprint(rf.score(X_test, y_test))\nprint(pd.crosstab(rf_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,rf_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "influence = pd.Series(rf.feature_importances_, index = X.columns)\ninfluence.sort_values(inplace = True, ascending = False)\nprint(influence[0:19])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## RF - oversampling\nrf.fit(X_train_over, y_train_over)\nrf_pred = rf.predict(X_test)\n\nprint(rf.score(X_test, y_test))\nprint(pd.crosstab(rf_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,rf_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X = X.drop(columns=['Price'])\ninfluence = pd.Series(rf.feature_importances_, index = X.columns)\ninfluence.sort_values(inplace = True, ascending = False)\nprint(influence[0:19])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## RF - Undersampling\nrf.fit(X_train_under, y_train_under)\nrf_pred = rf.predict(X_test)\n\nprint(rf.score(X_test, y_test))\nprint(pd.crosstab(rf_pred,y_test,rownames = [\"Predicted\"], colnames = [\"Actual\"]))\nprint(metrics.classification_report(y_test,rf_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "influence = pd.Series(rf.feature_importances_, index = X.columns)\ninfluence.sort_values(inplace = True, ascending = False)\nprint(influence[0:19])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}